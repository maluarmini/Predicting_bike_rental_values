# -*- coding: utf-8 -*-
"""Predicting Bike Rental Values.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ft2e4VIQENYm80cwPvLSJnLZEoeMe2hY
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
# %matplotlib inline

from google.colab import drive
drive.mount('/content/drive')

bike_rentals = pd.read_csv("/content/drive/My Drive/bike_rental_hour.csv")

bike_rentals.head()

bike_rentals.describe()

plt.figure(figsize=(12,8))
sns.set_style('darkgrid')
sns.distplot(bike_rentals.cnt)

# Calcular a correlação entre as variaveis
bike_rentals.corr()

# Filtrar as correlações com a minha variavel target 'cnt'
correlations = bike_rentals.corr()
correlations['cnt']

columns = bike_rentals.columns.drop(['cnt', 'casual', 'dteday', 'registered'])
columns

from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test = train_test_split(bike_rentals[columns], bike_rentals['cnt'],test_size=0.2,random_state=42)

algoritmo = LinearRegression()

modelo = algoritmo.fit(X_train,y_train)

resultado = modelo.predict(X_test)

mean_squared_error(y_test, resultado)

modelo.score(X_test,y_test)

# mean_square_error muito alto
# score muito baixo
# modelo de regressão linear não está performando bem

resultados_treino = modelo.predict(X_train)

mean_squared_error(y_train, resultados_treino)

modelo.score(X_train,y_train)

# Arvore de decisão
algoritmo_tree = DecisionTreeRegressor()

modelo_tree = algoritmo_tree.fit(X_train,y_train)

resultado_tree = modelo_tree.predict(X_test)

mean_squared_error(y_test, resultado_tree)

modelo_tree.score(X_test,y_test)

# Random_forest
# missão de resolver o problema de overfitting
# que ocorre na arvore de decisão atraves de metodo ensemble
tree_rf = RandomForestRegressor()

modelo_tree_rf = tree_rf.fit(X_train,y_train)

resultado_tree_rf = modelo_tree_rf.predict(X_test)

mean_squared_error(y_test,resultado_tree_rf)

modelo_tree_rf.score(X_train,y_train)

# Ajustando os Hiperparametros do random Forest

from sklearn.model_selection import GridSearchCV
# testes exaustivos e encontrar os melhores parametros

parametros = {'min_samples_leaf':[1,10],'min_samples_split':[2,10],'n_estimators':[100,250,500,750]}

# instanciando o RandomForest e GridSearch
rf = RandomForestRegressor()
grid = GridSearchCV(rf, parametros)

grid.fit(X_train,y_train)

grid.best_params_

rf_best = grid.best_estimator_

resultado_final = rf_best.predict(X_test)

mean_squared_error(y_test,resultado_final)

rf_best.score(X_test,y_test)